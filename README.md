# Описание архитектуры нейронной сети
В данной лабораторной работе мы обучали сверточную нейронную сеть для решения задачи классификации изображений дикой природы Oregon wildlife. Данный датасет Oregon_wildlife включает в себя около 12.000 картинок дикой природы, которые распределены на 20 различных категорий. Для обучения нашей нейронной сети мы использовали 50 эпох, т.е. весь наш датасет пройдет через нейронную сеть 50 раз. Каждую эпоху мы раздели на части (батчи) размером 512 объектов в каждом батче. 
*  Размерность входного изображения (224x224x3): 
```
inputs = tf.keras.Input(shape=(RESIZE_TO, RESIZE_TO, 3))
```
***
* Сверточные слои добавлены к нашей нейронной сети с использованием следующей функции Conv2D:  
```
x = tf.keras.layers.Conv2D(filters=8, kernel_size=3)(inputs)
```
Всего в одном сверточном слое у нас 8 фильтров, каждый фильтр будет применяться к изображению. Размерность матрицы ядра (фильтра) состовляет 3x3.
***
Благодаря ядру мы постепенно “скользим” по нашему изображению  и выполняем операцию свертки, а именно, поэлементно умножаем элементы нашего изображения на соответствующие элементы матрицы ядра и затем все эти произведения суммируем между собой. Далее с определенным шагом мы переходим к следующей части нашего изображения. Таким образом, наше ядро будет перемещаться по всему изображению с определенным шагом. Соответственно на выходе мы получаем некоторую выходную матрицу с элементами, которые получились в результате свертки. На выходе уменьшиться размерность (она станет 222x222x8, так как в картинку размером 224x224 поместятся только 222x222 окон свертки размером 3x3)  
*** 
* После получения свернутого изображения производится операция подвыборки (Max-Pooling):  
```
x = tf.keras.layers.MaxPool2D()(x)
```
Данная операция позволяет сгруппировать пиксели изображения и уплотнить их, т.е. уменьшить размер матрицы признаков (на выходе получим тензор размеров 111x111x8). Она сгруппирует пиксели в участке определенного размера (2x2) и выберет элемент с наибольшим значением, поэтому мы сожмем изображение и подчеркнем некоторые признаки.
***
* Flatten слой, позволяющий преобразовать наш многомерный тензор в одномерный (1D). На выходе получим одномерный массив размеров 111*111*8=98568
```
x = tf.keras.layers.Flatten()(x)
```
***
* Полносвязный Dense слой
```
outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax)(x)
```
Здесь мы и определяем к какому классу из 20 возможных будет относится поданное на вход изображение, а именно функция активации softmax даст вероятность того, что поданное на вход изображение относится к определенному числу (из 20 возможных).
***
Для того чтобы увеличить количество сверточных слоев мы добавили еще 3 дополнительных сверточных двумерных слоя, с помощью Conv2D и к ним добавили 3 подвыборочных слоя Max-Pooling (выбор максимального). 
```
x = tf.keras.layers.Conv2D(filters=8, kernel_size=3)(inputs)  
x = tf.keras.layers.MaxPool2D()(x)  
x = tf.keras.layers.Conv2D(filters=8, kernel_size=3)(inputs)  
x = tf.keras.layers.MaxPool2D()(x)  
x = tf.keras.layers.Conv2D(filters=8, kernel_size=3)(inputs)  
x = tf.keras.layers.MaxPool2D()(x)  
x = tf.keras.layers.Conv2D(filters=8, kernel_size=3)(inputs)  
x = tf.keras.layers.MaxPool2D()(x)
```
***
В результате получили двумерную сверточную нейронную сеть с количеством сверточных слоев 4.   
# После обучения данных нейронных сетей получили следующие графики:
График точности для сверточной нейронной сети с одним сверточных слоем:
![accuracy 512_batch_size](https://user-images.githubusercontent.com/59259102/110211637-342a8100-7ea0-11eb-92d8-e1555b53729e.jpg)  
График потерь для сверточной нейронной сети с одним сверточных слоем:
![loss 512_batch_size](https://user-images.githubusercontent.com/59259102/110211665-50c6b900-7ea0-11eb-851d-3d5912691f13.jpg)

